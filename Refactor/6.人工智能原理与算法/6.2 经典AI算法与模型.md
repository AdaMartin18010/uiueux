# 6.2 经典AI算法与模型

# [返回6.人工智能原理与算法](6.人工智能原理与算法/README.md) |  [返回Refactor总览](6.人工智能原理与算法/../README.md)

# ---

## 2024前沿趋势

# - **经典算法现代化**：传统算法的GPU加速、分布式实现。
# - **混合算法**：经典算法与深度学习的结合、神经符号AI。
# - **算法优化**：量子算法、近似算法、随机化算法。
# - **可解释性**：决策树、规则学习、符号推理的复兴。
# - **小样本学习**：Few-shot Learning、Meta Learning、迁移学习。
# - **因果推理**：因果发现、反事实推理、因果机器学习。

# ---

## 目录

# - [6.2 经典AI算法与模型](#62-经典ai算法与模型)
#   - [2024前沿趋势](#2024前沿趋势)
#   - [目录](#目录)
#   - [6.2.1 算法分类Mermaid图](#621-算法分类mermaid图)
#   - [8. 相关主题推荐阅读](#8-相关主题推荐阅读)

# ---

## 6.2.1 算法分类Mermaid图

# ```mermaid
# graph TD
#     A[AI算法] --> B[监督学习]
#     A --> C[无监督学习]
#     A --> D[强化学习]
#     A --> E[集成学习]

#     B --> F[决策树]
#     B --> G[支持向量机]
#     B --> H[朴素贝叶斯]
#     B --> I[K近邻]
#     B --> J[线性回归]
#     B --> K[逻辑回归]

#     C --> L[K均值聚类]
#     C --> M[层次聚类]
#     C --> N[主成分分析]
#     C --> O[自编码器]

#     D --> P[Q-Learning]
#     D --> Q[Policy Gradient]
#     D --> R[Actor-Critic]
#     D --> S[Deep Q-Network]

#     E --> T[Bagging]
#     E --> U[Boosting]
#     E --> V[Random Forest]
#     E --> W[Stacking]
# ```css
# ---

## 6.2.2 算法复杂度LaTeX公式

# **时间复杂度**:
# $$
# T(n) = O(f(n)) /text{ where } /lim_{n /to /infty} /frac{T(n)}{f(n)} = c
# $$

# **空间复杂度**:
# $$
# S(n) = O(g(n)) /text{ where } /lim_{n /to /infty} /frac{S(n)}{g(n)} = c
# $$

# **决策树信息增益**:
# $$
# IG(S, A) = H(S) - /sum_{v /in Values(A)} /frac{ | S_v |}{| S | } H(S_v)
# $$

# 其中：
# $$
# H(S) = -/sum_{i=1}^{c} p_i /log_2 p_i
# $$

# **支持向量机对偶问题**:
# $$
# /max_{/alpha} /sum_{i=1}^{n} /alpha_i - /frac{1}{2} /sum_{i,j=1}^{n} /alpha_i /alpha_j y_i y_j K(x_i, x_j)
# $$

# 约束条件：
# $$
# /sum_{i=1}^{n} /alpha_i y_i = 0, /quad 0 /leq /alpha_i /leq C
# $$

# **K均值聚类目标函数**:
# $$
# J = /sum_{i=1}^{k} /sum_{x /in C_i} / |x - /mu_i/| ^2
# $$

# 其中：
# $$
# /mu_i = /frac{1}{ | C_i |} /sum_{x /in C_i} x
# $$

# **Q-Learning更新规则**:
# $$
# Q(s, a) /leftarrow Q(s, a) + /alpha [r + /gamma /max_{a'} Q(s', a') - Q(s, a)]
# $$

# ---

## 6.2.3 经典算法代码示例

# **决策树算法**:
# ```python
# import numpy as np
# from collections import Counter
# import math

# class DecisionTree:
#     def __init__(self, max_depth=None, min_samples_split=2):
#         self.max_depth = max_depth
#         self.min_samples_split = min_samples_split
#         self.tree = None

#     def entropy(self, y):
#         """计算信息熵"""
#         counts = Counter(y)
#         probabilities = [count / len(y) for count in counts.values()]
#         return -sum(p * math.log2(p) for p in probabilities if p > 0)

#     def information_gain(self, X, y, feature_idx, threshold):
#         """计算信息增益"""
#         parent_entropy = self.entropy(y)

#         # 分割数据
#         left_mask = X[:, feature_idx] <= threshold
#         right_mask = ~left_mask

#         if not np.any(left_mask) or not np.any(right_mask):
#             return 0

#         # 计算子节点熵
#         left_entropy = self.entropy(y[left_mask])
#         right_entropy = self.entropy(y[right_mask])

#         # 计算加权平均熵
#         left_weight = np.sum(left_mask) / len(y)
#         right_weight = np.sum(right_mask) / len(y)
#         weighted_entropy = left_weight * left_entropy + right_weight * right_entropy

#         return parent_entropy - weighted_entropy

#     def find_best_split(self, X, y):
#         """找到最佳分割点"""
#         best_gain = 0
#         best_feature = None
#         best_threshold = None

#         n_features = X.shape[1]

#         for feature_idx in range(n_features):
#             thresholds = np.unique(X[:, feature_idx])

#             for threshold in thresholds:
#                 gain = self.information_gain(X, y, feature_idx, threshold)

#                 if gain > best_gain:
#                     best_gain = gain
#                     best_feature = feature_idx
#                     best_threshold = threshold

#         return best_feature, best_threshold

#     def create_leaf(self, y):
#         """创建叶子节点"""
#         return {'type': 'leaf', 'prediction': Counter(y).most_common(1)[0][0]}

#     def create_node(self, feature_idx, threshold, left_tree, right_tree):
#         """创建内部节点"""
#         return {
#             'type': 'node',
#             'feature_idx': feature_idx,
#             'threshold': threshold,
#             'left': left_tree,
#             'right': right_tree
#         }

#     def build_tree(self, X, y, depth=0):
#         """构建决策树"""
#         n_samples, n_features = X.shape
#         n_classes = len(np.unique(y))

#         # 停止条件
#         if (self.max_depth is not None and depth >= self.max_depth) or /
#            n_samples < self.min_samples_split or /
#            n_classes == 1:
#             return self.create_leaf(y)

#         # 找到最佳分割
#         best_feature, best_threshold = self.find_best_split(X, y)

#         if best_feature is None:
#             return self.create_leaf(y)

#         # 分割数据
#         left_mask = X[:, best_feature] <= best_threshold
#         right_mask = ~left_mask

#         # 递归构建子树
#         left_tree = self.build_tree(X[left_mask], y[left_mask], depth + 1)
#         right_tree = self.build_tree(X[right_mask], y[right_mask], depth + 1)

#         return self.create_node(best_feature, best_threshold, left_tree, right_tree)

#     def fit(self, X, y):
#         """训练决策树"""
#         self.tree = self.build_tree(X, y)
#         return self

#     def predict_single(self, x, tree):
#         """预测单个样本"""
#         if tree['type'] == 'leaf':
#             return tree['prediction']

#         if x[tree['feature_idx']] <= tree['threshold']:
#             return self.predict_single(x, tree['left'])
#         else:
#             return self.predict_single(x, tree['right'])

#     def predict(self, X):
#         """预测多个样本"""
#         return [self.predict_single(x, self.tree) for x in X]

# 使用示例
# from sklearn.datasets import make_classification
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import accuracy_score

# 生成数据
# X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 训练决策树
# dt = DecisionTree(max_depth=5)
# dt.fit(X_train, y_train)

# 预测
# y_pred = dt.predict(X_test)
# accuracy = accuracy_score(y_test, y_pred)
# print(f"决策树准确率: {accuracy:.4f}")
# ```text
# **支持向量机算法**:
# ```python
# import numpy as np
# from scipy.optimize import minimize

# class SVM:
#     def __init__(self, C=1.0, kernel='linear'):
#         self.C = C
#         self.kernel = kernel
#         self.alphas = None
#         self.support_vectors = None
#         self.support_vector_labels = None
#         self.b = 0

#     def linear_kernel(self, x1, x2):
#         """线性核函数"""
#         return np.dot(x1, x2)

#     def rbf_kernel(self, x1, x2, gamma=1.0):
#         """RBF核函数"""
#         return np.exp(-gamma * np.linalg.norm(x1 - x2) ** 2)

#     def polynomial_kernel(self, x1, x2, degree=3):
#         """多项式核函数"""
#         return (np.dot(x1, x2) + 1) ** degree

#     def compute_kernel_matrix(self, X):
#         """计算核矩阵"""
#         n_samples = X.shape[0]
#         K = np.zeros((n_samples, n_samples))

#         for i in range(n_samples):
#             for j in range(n_samples):
#                 if self.kernel == 'linear':
#                     K[i, j] = self.linear_kernel(X[i], X[j])
#                 elif self.kernel == 'rbf':
#                     K[i, j] = self.rbf_kernel(X[i], X[j])
#                 elif self.kernel == 'poly':
#                     K[i, j] = self.polynomial_kernel(X[i], X[j])

#         return K

#     def objective_function(self, alphas, K, y):
#         """对偶问题的目标函数"""
#         return 0.5 * np.sum(alphas[:, np.newaxis] * alphas[np.newaxis, :] *
#                            y[:, np.newaxis] * y[np.newaxis, :] * K) - np.sum(alphas)

#     def fit(self, X, y):
#         """训练SVM"""
#         n_samples = X.shape[0]

#         # 计算核矩阵
#         K = self.compute_kernel_matrix(X)

#         # 约束条件
#         constraints = [
#             {'type': 'eq', 'fun': lambda alphas: np.sum(alphas * y)},
#             {'type': 'ineq', 'fun': lambda alphas: alphas},
#             {'type': 'ineq', 'fun': lambda alphas: self.C - alphas}
#         ]

#         # 优化
#         result = minimize(
#             fun=lambda alphas: self.objective_function(alphas, K, y),
#             x0=np.zeros(n_samples),
#             method='SLSQP',
#             constraints=constraints,
#             bounds=[(0, self.C)] * n_samples
#         )

#         self.alphas = result.x

#         # 找到支持向量
#         support_vector_indices = self.alphas > 1e-5
#         self.support_vectors = X[support_vector_indices]
#         self.support_vector_labels = y[support_vector_indices]
#         self.support_vector_alphas = self.alphas[support_vector_indices]

#         # 计算偏置项
#         self.b = np.mean(y[support_vector_indices] -
#                         np.sum(self.support_vector_alphas[:, np.newaxis] *
#                                self.support_vector_labels[:, np.newaxis] *
#                                K[support_vector_indices][:, support_vector_indices], axis=0))

#     def predict(self, X):
#         """预测"""
#         predictions = []

#         for x in X:
#             prediction = 0
#             for i, (sv, sv_label, sv_alpha) in enumerate(zip(
#                 self.support_vectors, self.support_vector_labels, self.support_vector_alphas)):

#                 if self.kernel == 'linear':
#                     kernel_value = self.linear_kernel(x, sv)
#                 elif self.kernel == 'rbf':
#                     kernel_value = self.rbf_kernel(x, sv)
#                 elif self.kernel == 'poly':
#                     kernel_value = self.polynomial_kernel(x, sv)

#                 prediction += sv_alpha * sv_label * kernel_value

#             prediction += self.b
#             predictions.append(1 if prediction > 0 else -1)

#         return np.array(predictions)

# 使用示例
# from sklearn.datasets import make_classification
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import accuracy_score

# 生成数据
# X, y = make_classification(n_samples=200, n_features=2, n_classes=2,
#                           n_clusters_per_class=1, n_redundant=0, random_state=42)
# y = np.where(y == 0, -1, 1)  # 转换为-1和1

# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 训练SVM
# svm = SVM(C=1.0, kernel='rbf')
# svm.fit(X_train, y_train)

# 预测
# y_pred = svm.predict(X_test)
# accuracy = accuracy_score(y_test, y_pred)
# print(f"SVM准确率: {accuracy:.4f}")
# ```text
# **K均值聚类算法**:
# ```python
# import numpy as np
# import matplotlib.pyplot as plt
# from sklearn.datasets import make_blobs

# class KMeans:
#     def __init__(self, n_clusters=3, max_iters=100, random_state=42):
#         self.n_clusters = n_clusters
#         self.max_iters = max_iters
#         self.random_state = random_state
#         self.centroids = None
#         self.labels = None
#         self.inertia_ = None

#     def initialize_centroids(self, X):
#         """初始化聚类中心"""
#         np.random.seed(self.random_state)
#         n_samples, n_features = X.shape
#         centroids = np.zeros((self.n_clusters, n_features))

#         # K-means++初始化
#         centroids[0] = X[np.random.randint(n_samples)]

#         for i in range(1, self.n_clusters):
#             distances = np.min([np.sum((X - centroid) ** 2, axis=1)
#                               for centroid in centroids[:i]], axis=0)
#             probabilities = distances / np.sum(distances)
#             cumulative_probabilities = np.cumsum(probabilities)
#             r = np.random.random()
#             j = np.where(cumulative_probabilities >= r)[0][0]
#             centroids[i] = X[j]

#         return centroids

#     def assign_clusters(self, X, centroids):
#         """分配样本到最近的聚类中心"""
#         distances = np.sqrt(((X - centroids[:, np.newaxis]) ** 2).sum(axis=2))
#         return np.argmin(distances, axis=0)

#     def update_centroids(self, X, labels):
#         """更新聚类中心"""
#         centroids = np.zeros((self.n_clusters, X.shape[1]))
#         for k in range(self.n_clusters):
#             if np.sum(labels == k) > 0:
#                 centroids[k] = np.mean(X[labels == k], axis=0)
#         return centroids

#     def compute_inertia(self, X, labels, centroids):
#         """计算惯性（簇内平方和）"""
#         inertia = 0
#         for k in range(self.n_clusters):
#             cluster_points = X[labels == k]
#             if len(cluster_points) > 0:
#                 inertia += np.sum((cluster_points - centroids[k]) ** 2)
#         return inertia

#     def fit(self, X):
#         """训练K均值聚类"""
#         # 初始化聚类中心
#         self.centroids = self.initialize_centroids(X)

#         for iteration in range(self.max_iters):
#             # 分配样本到聚类
#             old_labels = self.labels.copy() if self.labels is not None else None
#             self.labels = self.assign_clusters(X, self.centroids)

#             # 检查收敛
#             if old_labels is not None and np.all(old_labels == self.labels):
#                 break

#             # 更新聚类中心
#             self.centroids = self.update_centroids(X, self.labels)

#         # 计算最终惯性
#         self.inertia_ = self.compute_inertia(X, self.labels, self.centroids)

#         return self

#     def predict(self, X):
#         """预测新样本的聚类标签"""
#         return self.assign_clusters(X, self.centroids)

#     def fit_predict(self, X):
#         """训练并预测"""
#         self.fit(X)
#         return self.labels

# 使用示例
# 生成数据
# X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=42)

# 训练K均值聚类
# kmeans = KMeans(n_clusters=4, max_iters=100)
# labels = kmeans.fit_predict(X)

# 可视化结果
# plt.figure(figsize=(12, 4))

# plt.subplot(1, 2, 1)
# plt.scatter(X[:, 0], X[:, 1], c=y_true, cmap='viridis')
# plt.title('真实聚类')
# plt.xlabel('特征1')
# plt.ylabel('特征2')

# plt.subplot(1, 2, 2)
# plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
# plt.scatter(kmeans.centroids[:, 0], kmeans.centroids[:, 1],
#            c='red', marker='x', s=200, linewidths=3, label='聚类中心')
# plt.title('K均值聚类结果')
# plt.xlabel('特征1')
# plt.ylabel('特征2')
# plt.legend()

# plt.tight_layout()
# plt.show()

# print(f"聚类惯性: {kmeans.inertia_:.4f}")
# ```text
# **Q-Learning算法**:
# ```python
# import numpy as np
# import random
# import matplotlib.pyplot as plt

# class QLearningAgent:
#     def __init__(self, state_size, action_size, learning_rate=0.1,
#                  discount_factor=0.95, epsilon=0.1):
#         self.state_size = state_size
#         self.action_size = action_size
#         self.learning_rate = learning_rate
#         self.discount_factor = discount_factor
#         self.epsilon = epsilon
#         self.q_table = np.zeros((state_size, action_size))

#     def choose_action(self, state):
#         """选择动作（ε-贪婪策略）"""
#         if random.random() < self.epsilon:
#             return random.randint(0, self.action_size - 1)
#         else:
#             return np.argmax(self.q_table[state])

#     def learn(self, state, action, reward, next_state, done):
#         """学习更新Q值"""
#         old_value = self.q_table[state, action]

#         if done:
#             next_max = 0
#         else:
#             next_max = np.max(self.q_table[next_state])

#         new_value = (1 - self.learning_rate) * old_value + /
#                    self.learning_rate * (reward + self.discount_factor * next_max)

#         self.q_table[state, action] = new_value

#     def get_q_table(self):
#         return self.q_table

# class GridWorld:
#     def __init__(self, size=4):
#         self.size = size
#         self.state = 0
#         self.goal = size * size - 1
#         self.obstacles = [5, 7, 11]  # 障碍物位置

#     def reset(self):
#         self.state = 0
#         return self.state

#     def step(self, action):
#         # 动作: 0=上, 1=右, 2=下, 3=左
#         x, y = self.state // self.size, self.state % self.size

#         if action == 0:  # 上
#             x = max(0, x - 1)
#         elif action == 1:  # 右
#             y = min(self.size - 1, y + 1)
#         elif action == 2:  # 下
#             x = min(self.size - 1, x + 1)
#         elif action == 3:  # 左
#             y = max(0, y - 1)

#         new_state = x * self.size + y

#         # 检查是否撞到障碍物
#         if new_state in self.obstacles:
#             return self.state, -10, True

#         self.state = new_state

#         done = self.state == self.goal
#         reward = 1 if done else -0.01

#         return self.state, reward, done

#     def render(self):
#         """渲染环境"""
#         grid = [[' ' for _ in range(self.size)] for _ in range(self.size)]

#         # 标记目标
#         goal_x, goal_y = self.goal // self.size, self.goal % self.size
#         grid[goal_x][goal_y] = 'G'

#         # 标记障碍物
#         for obstacle in self.obstacles:
#             obs_x, obs_y = obstacle // self.size, obstacle % self.size
#             grid[obs_x][obs_y] = 'X'

#         # 标记智能体
#         agent_x, agent_y = self.state // self.size, self.state % self.size
#         grid[agent_x][agent_y] = 'A'

#         # 打印网格
#         for row in grid:
#             print('| ' + ' | '.join(row) + ' |')

# 训练函数
# def train_q_learning(env, agent, episodes=1000):
#     rewards_history = []

#     for episode in range(episodes):
#         state = env.reset()
#         total_reward = 0
#         steps = 0
#         max_steps = 100

#         while steps < max_steps:
#             action = agent.choose_action(state)
#             next_state, reward, done = env.step(action)

#             agent.learn(state, action, reward, next_state, done)

#             state = next_state
#             total_reward += reward
#             steps += 1

#             if done:
#                 break

#         rewards_history.append(total_reward)

#         if episode % 100 == 0:
#             avg_reward = np.mean(rewards_history[-100:])
#             print(f"Episode {episode}, Average Reward: {avg_reward:.2f}")

#     return rewards_history

# 使用示例
# env = GridWorld(4)
# agent = QLearningAgent(16, 4, learning_rate=0.1, discount_factor=0.95, epsilon=0.1)

# 训练
# rewards = train_q_learning(env, agent, episodes=1000)

# 可视化训练过程
# plt.figure(figsize=(12, 4))

# plt.subplot(1, 2, 1)
# plt.plot(rewards)
# plt.title('训练奖励')
# plt.xlabel('Episode')
# plt.ylabel('Total Reward')

# plt.subplot(1, 2, 2)
# window_size = 100
# moving_avg = np.convolve(rewards, np.ones(window_size)/window_size, mode='valid')
# plt.plot(moving_avg)
# plt.title('移动平均奖励')
# plt.xlabel('Episode')
# plt.ylabel('Average Reward')

# plt.tight_layout()
# plt.show()

# 测试训练好的智能体
# print("/n测试训练好的智能体:")
# env.reset()
# env.render()

# for step in range(10):
#     state = env.state
#     action = agent.choose_action(state)
#     next_state, reward, done = env.step(action)

#     print(f"/n步骤 {step + 1}:")
#     print(f"状态: {state}, 动作: {action}, 奖励: {reward}")
#     env.render()

#     if done:
#         print("到达目标!")
#         break
# ```text
# **随机森林算法**:
# ```python
# import numpy as np
# from collections import Counter
# import random

# class DecisionTree:
#     def __init__(self, max_depth=None, min_samples_split=2):
#         self.max_depth = max_depth
#         self.min_samples_split = min_samples_split
#         self.tree = None

#     def entropy(self, y):
#         counts = Counter(y)
#         probabilities = [count / len(y) for count in counts.values()]
#         return -sum(p * np.log2(p) for p in probabilities if p > 0)

#     def information_gain(self, X, y, feature_idx, threshold):
#         parent_entropy = self.entropy(y)

#         left_mask = X[:, feature_idx] <= threshold
#         right_mask = ~left_mask

#         if not np.any(left_mask) or not np.any(right_mask):
#             return 0

#         left_entropy = self.entropy(y[left_mask])
#         right_entropy = self.entropy(y[right_mask])

#         left_weight = np.sum(left_mask) / len(y)
#         right_weight = np.sum(right_mask) / len(y)
#         weighted_entropy = left_weight * left_entropy + right_weight * right_entropy

#         return parent_entropy - weighted_entropy

#     def find_best_split(self, X, y, feature_subset=None):
#         best_gain = 0
#         best_feature = None
#         best_threshold = None

#         n_features = X.shape[1]
#         features_to_check = feature_subset if feature_subset is not None else range(n_features)

#         for feature_idx in features_to_check:
#             thresholds = np.unique(X[:, feature_idx])

#             for threshold in thresholds:
#                 gain = self.information_gain(X, y, feature_idx, threshold)

#                 if gain > best_gain:
#                     best_gain = gain
#                     best_feature = feature_idx
#                     best_threshold = threshold

#         return best_feature, best_threshold

#     def create_leaf(self, y):
#         return {'type': 'leaf', 'prediction': Counter(y).most_common(1)[0][0]}

#     def create_node(self, feature_idx, threshold, left_tree, right_tree):
#         return {
#             'type': 'node',
#             'feature_idx': feature_idx,
#             'threshold': threshold,
#             'left': left_tree,
#             'right': right_tree
#         }

#     def build_tree(self, X, y, depth=0, feature_subset=None):
#         n_samples, n_features = X.shape
#         n_classes = len(np.unique(y))

#         if (self.max_depth is not None and depth >= self.max_depth) or /
#            n_samples < self.min_samples_split or /
#            n_classes == 1:
#             return self.create_leaf(y)

#         best_feature, best_threshold = self.find_best_split(X, y, feature_subset)

#         if best_feature is None:
#             return self.create_leaf(y)

#         left_mask = X[:, best_feature] <= best_threshold
#         right_mask = ~left_mask

#         left_tree = self.build_tree(X[left_mask], y[left_mask], depth + 1, feature_subset)
#         right_tree = self.build_tree(X[right_mask], y[right_mask], depth + 1, feature_subset)

#         return self.create_node(best_feature, best_threshold, left_tree, right_tree)

#     def fit(self, X, y, feature_subset=None):
#         self.tree = self.build_tree(X, y, feature_subset=feature_subset)
#         return self

#     def predict_single(self, x, tree):
#         if tree['type'] == 'leaf':
#             return tree['prediction']

#         if x[tree['feature_idx']] <= tree['threshold']:
#             return self.predict_single(x, tree['left'])
#         else:
#             return self.predict_single(x, tree['right'])

#     def predict(self, X):
#         return [self.predict_single(x, self.tree) for x in X]

# class RandomForest:
#     def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2,
#                  max_features='sqrt', bootstrap=True, random_state=42):
#         self.n_estimators = n_estimators
#         self.max_depth = max_depth
#         self.min_samples_split = min_samples_split
#         self.max_features = max_features
#         self.bootstrap = bootstrap
#         self.random_state = random_state
#         self.trees = []
#         self.feature_subsets = []

#     def bootstrap_sample(self, X, y):
#         """生成bootstrap样本"""
#         n_samples = X.shape[0]
#         indices = np.random.choice(n_samples, size=n_samples, replace=True)
#         return X[indices], y[indices]

#     def get_feature_subset(self, n_features):
#         """获取特征子集"""
#         if self.max_features == 'sqrt':
#             n_subset = int(np.sqrt(n_features))
#         elif self.max_features == 'log2':
#             n_subset = int(np.log2(n_features))
#         elif isinstance(self.max_features, float):
#             n_subset = int(self.max_features * n_features)
#         else:
#             n_subset = n_features

#         return np.random.choice(n_features, size=n_subset, replace=False)

#     def fit(self, X, y):
#         """训练随机森林"""
#         np.random.seed(self.random_state)
#         n_features = X.shape[1]

#         for i in range(self.n_estimators):
#             # 生成bootstrap样本
#             if self.bootstrap:
#                 X_sample, y_sample = self.bootstrap_sample(X, y)
#             else:
#                 X_sample, y_sample = X, y

#             # 获取特征子集
#             feature_subset = self.get_feature_subset(n_features)

#             # 训练决策树
#             tree = DecisionTree(
#                 max_depth=self.max_depth,
#                 min_samples_split=self.min_samples_split
#             )
#             tree.fit(X_sample, y_sample, feature_subset=feature_subset)

#             self.trees.append(tree)
#             self.feature_subsets.append(feature_subset)

#         return self

#     def predict(self, X):
#         """预测"""
#         predictions = []

#         for x in X:
#             tree_predictions = []
#             for tree in self.trees:
#                 tree_predictions.append(tree.predict_single(x, tree.tree))

#             # 多数投票
#             prediction = Counter(tree_predictions).most_common(1)[0][0]
#             predictions.append(prediction)

#         return predictions

#     def predict_proba(self, X):
#         """预测概率"""
#         predictions = []

#         for x in X:
#             tree_predictions = []
#             for tree in self.trees:
#                 tree_predictions.append(tree.predict_single(x, tree.tree))

#             # 计算概率
#             counter = Counter(tree_predictions)
#             total = len(tree_predictions)
#             probabilities = {label: count / total for label, count in counter.items()}
#             predictions.append(probabilities)

#         return predictions

# 使用示例
# from sklearn.datasets import make_classification
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import accuracy_score, classification_report

# 生成数据
# X, y = make_classification(n_samples=1000, n_features=20, n_classes=2,
#                           n_informative=10, n_redundant=5, random_state=42)

# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 训练随机森林
# rf = RandomForest(n_estimators=100, max_depth=10, max_features='sqrt')
# rf.fit(X_train, y_train)

# 预测
# y_pred = rf.predict(X_test)
# accuracy = accuracy_score(y_test, y_pred)

# print(f"随机森林准确率: {accuracy:.4f}")
# print("/n分类报告:")
# print(classification_report(y_test, y_pred))

# 特征重要性（简化版本）
# def feature_importance(rf, X, y):
#     """计算特征重要性"""
#     n_features = X.shape[1]
#     importances = np.zeros(n_features)

#     for tree, feature_subset in zip(rf.trees, rf.feature_subsets):
#         # 这里简化处理，实际应该计算每个特征的信息增益
#         for feature in feature_subset:
#             importances[feature] += 1

#     return importances / len(rf.trees)

# importances = feature_importance(rf, X_train, y_train)
# print("/n特征重要性:")
# for i, importance in enumerate(importances):
#     print(f"特征 {i}: {importance:.4f}")
# ```

# ---

## 8. 相关主题推荐阅读

# - [2.1 前端主流框架](6.人工智能原理与算法/../2.技术栈与框架/2.1 前端主流框架.md)
# - [2.3 Rust前端全栈](6.人工智能原理与算法/../2.技术栈与框架/2.3 Rust前端全栈.md)
# - [3.1 Rust](6.人工智能原理与算法/../3.编程语言范式/3.1 Rust.md)
# - [6.1 AI基础原理](6.人工智能原理与算法/6.1 AI基础原理.md)
# - [6.3 现代深度学习与大模型](6.人工智能原理与算法/6.3 现代深度学习与大模型.md)
# - [6.4 AI工程实践与伦理](6.人工智能原理与算法/6.4 AI工程实践与伦理.md)
# - [6.5 AI与哲学](6.人工智能原理与算法/6.5 AI与哲学.md)

# ---

# > 本文档持续递归优化，欢迎补充最新技术与学术内容。
